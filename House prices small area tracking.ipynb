{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdea4a0f",
   "metadata": {},
   "source": [
    "# Analysing HMLR domestic property sale Â£ prices using the HMLR 'Price Paid' dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097a03fd",
   "metadata": {},
   "source": [
    "The method identifies change between 2012 - 2022 for individual properties in England and Wales including metrics for urban-rural classification, regional patterns, and property type, checking counts for statistical significance.\n",
    "The method uses Python 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300d878f",
   "metadata": {},
   "source": [
    "A BIT ABOUT THE DIMENSIONS OF THE PRICE PAID DATA AND WHY IT IS USEFUL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdfc350",
   "metadata": {},
   "source": [
    "The data can be downloaded as a flat file from https://www.gov.uk/government/statistical-data-sets/price-paid-data-downloads ('the complete Price Paid Transaction Data as a CSV file') which shows some discovery metadata, or accessed as json via an API at https://landregistry.data.gov.uk/data/ppi.json in 2023. Additional metadata can be found at https://landregistry.data.gov.uk/app/root/doc/ppd#:~:text=The%20price%20paid%20dataset%20is%20available%20in%20several,to%20use%20under%20the%20terms%20of%20the%20OGL.  Data is open government data under OGL licence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8d79c6",
   "metadata": {},
   "source": [
    "Additional optional contextual country boundaries for the purposes of visualisation can be downloaded as open data from https://geoportal.statistics.gov.uk/datasets/ons::countries-december-2022-boundaries-gb-bfc/explore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9075fab",
   "metadata": {},
   "source": [
    "A combination of spatial and non-spatial analysis libraries are used for the data engineering, and matplotlib to show some basic trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25be8419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "import geopandas\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6889aa4e",
   "metadata": {},
   "source": [
    "Firstly, import the 'price paid' data for both 2012 and 2022 with relevant headers and specified datatypes from the flat files into a dataframe. An API method could be considered: for context we are interested in querying the entire dataset initially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "223fac3c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pp-2012-part1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m colnames\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpricepaid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpostcode\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproptype\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtenure\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPAON\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSAON\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstreet\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      2\u001b[0m type_dict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpricepaid\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpostcode\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproptype\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtenure\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPAON\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSAON\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstreet\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[1;32m----> 3\u001b[0m pp_2012_pt1 \u001b[38;5;241m=\u001b[39m \u001b[43mpandas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpp-2012-part1.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolnames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtype_dict\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m pp_2012_pt2 \u001b[38;5;241m=\u001b[39m pandas\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpp-2012-part2.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, usecols\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m9\u001b[39m], names\u001b[38;5;241m=\u001b[39mcolnames )\n\u001b[0;32m      5\u001b[0m pp_2022 \u001b[38;5;241m=\u001b[39m pandas\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpp-2022.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, usecols\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m9\u001b[39m], names\u001b[38;5;241m=\u001b[39mcolnames )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pp-2012-part1.csv'"
     ]
    }
   ],
   "source": [
    "colnames=['pricepaid', 'date','postcode', 'proptype', 'tenure', 'PAON', 'SAON', 'street']\n",
    "type_dict = {'pricepaid': 'int', 'date': 'str', 'postcode': 'str', 'proptype': 'str', 'tenure': 'str', 'PAON':'str', 'SAON':'str', 'street': 'str'}\n",
    "pp_2012_pt1 = pandas.read_csv('pp-2012-part1.csv', usecols=[1,2,3,4,6,7,8,9], names=colnames, dtype=type_dict )\n",
    "pp_2012_pt2 = pandas.read_csv('pp-2012-part2.csv', usecols=[1,2,3,4,6,7,8,9], names=colnames )\n",
    "pp_2022 = pandas.read_csv('pp-2022.csv', usecols=[1,2,3,4,6,7,8,9], names=colnames )\n",
    "pp_2012_pt1.date = pandas.to_datetime(pp_2012_pt1['date'])# convert dates to datetime data type \n",
    "pp_2012_pt2.date = pandas.to_datetime(pp_2012_pt2['date'])\n",
    "pp_2022.date = pandas.to_datetime(pp_2022['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab124e56",
   "metadata": {},
   "source": [
    "The columns should be relatively self-explanatory:\n",
    "    pricepaid - is the transaction price paid for the property at the point of sale in Â£\n",
    "    date - is the date of the Â£ transaction, or in UK terms the 'completion date'\n",
    "    postcode - is the full postcode unit of the property\n",
    "    proptype - is the property type - a standard taxonomy of either detatched / semi-detached / terraced / flat or maisonette / other\n",
    "    tenure - is the legal tenure under which the property is held, either freehold or leasehold \n",
    "    PAON - is the primary addressable object name or number of the property, aligned to the British BBS7666 format for addressing\n",
    "    SAON - is the secondary addressable object name or number of the property, aligned to the British BS7666 format for addressing\n",
    "    street - is the street name of the property\n",
    "    \n",
    " We are most interested in the first 5 fields only, as the data are 'geocoded' or located in space based on coordinates available for postcode information. More about this below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e1f7da",
   "metadata": {},
   "source": [
    "Historic 2012 is currently available in 2 files, so append the 2012 data together, row-wise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40752fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_2012 = pp_2012_pt1.append(pp_2012_pt2, ignore_index=True)\n",
    "pp_2012_pt1.drop(pp_2012_pt1.index , inplace=True)\n",
    "pp_2012_pt2.drop(pp_2012_pt2.index , inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a883cf",
   "metadata": {},
   "source": [
    "The method aims to identify houses, flats etc - the exact property of which - has been sold both in the year 2012 and again in the year 2022, to track change over time. In order to create record-level matches a new field is required in each input dataframe to act as unique ID to identify the same property record. A combination of the postcode, PAON, SAON and street can achieve this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5be60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_2012['concat2012'] = pp_2012['postcode'] + pp_2012['PAON'] + pp_2012['SAON'].astype(str) + pp_2012['street']\n",
    "pp_2022['concat2022'] = pp_2022['postcode'] + pp_2022['PAON'] + pp_2022['SAON'].astype(str) + pp_2022['street']\n",
    "pp_2012.drop(['PAON', 'SAON', 'street'], axis=1, inplace=True) #no longer needed\n",
    "pp_2022.drop(['PAON', 'SAON', 'street'], axis=1, inplace=True) #no longer needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b79275e",
   "metadata": {},
   "source": [
    "Some properties are sold multiple times within the 12 month period. We can identify recs sold multiple times in the year and delete before joining:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627f7813",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates_2012 = pp_2012[pp_2012.duplicated(['concat2012'], keep=False)]\n",
    "duplicates_2022 = pp_2022[pp_2022.duplicated(['concat2022'], keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8220a3f5",
   "metadata": {},
   "source": [
    "The assumptions made are to use the earliest sale from the 2012 data and the latest sale from the 2022 data in these cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0722e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "todelete_2012 = duplicates_2012.sort_values('date').drop_duplicates('concat2012',keep='first') \n",
    "todelete_2022 = duplicates_2022.sort_values('date').drop_duplicates('concat2022',keep='last') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69188731",
   "metadata": {},
   "source": [
    "and then delete them from the main dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59dea93",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = pp_2012['concat2012'].isin(todelete_2012['concat2012']) # first df is the records to keep, second df contains the records to delete\n",
    "pp_2012.drop(pp_2012[cond].index, inplace = True)\n",
    "cond = pp_2022['concat2022'].isin(todelete_2022['concat2022']) # first df is the records to keep, second df contains the records to delete\n",
    "pp_2022.drop(pp_2022[cond].index, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9231a9ca",
   "metadata": {},
   "source": [
    "The date field is no longer needed at this point so can be dropped:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fc9db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_2012.drop(['date'], axis=1, inplace=True)\n",
    "pp_2022.drop(['date'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7a812d",
   "metadata": {},
   "source": [
    "There are some records in the raw data that do not contain location information - these are deleted before joining the dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5878001",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_2012.drop(pp_2012[pp_2012['concat2012'].isnull()].index, inplace = True) # 658,717 recs remaining\n",
    "pp_2022.drop(pp_2022[pp_2022['concat2022'].isnull()].index, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd80b82",
   "metadata": {},
   "source": [
    "The property records between 2012 and 2022 dataframes are then inner joined on the 'concat' field previously calculated.\n",
    "\n",
    "There are 30,301 joined recs. Based on the 24,782,800 households England and Wales recorded at the Census in March 2021, this is an estimated 0.12% sample of domestic properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e674b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = pp_2012.merge(pp_2022, left_on='concat2012', right_on='concat2022', how='inner') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f6e703",
   "metadata": {},
   "source": [
    "The original and new transaction prices are now contained within a new dataframe for each individual property. A % increase or 'price paid' is calculated in a new field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b7360e",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined['perchange'] = (joined['pricepaid_y'] - joined['pricepaid_x']) / joined['pricepaid_y'] *100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4e9b9b",
   "metadata": {},
   "source": [
    "In order to look at any geographic patterns we need to geocode or locate the properties in space to perform some basic spatial analysis. Full address-matching would give a very precise property location but is both a. not necessary for the scale-dependency of the analysis, and b. relatively complex and time-consuming. This method uses the full 'unit' postcode information and the coordinates available, which will locate the properties to the centre of around 15 spatially contiguous addresses. \n",
    "\n",
    "The Office for National Statistics Postcode Directory (ONSPD) is available as open data in order to do this. It can be downloded from https://geoportal.statistics.gov.uk as a flat file, released quarterly. There is no open API available in 2023, and so this data is imported from csv into a new dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06eaa7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "onspd = pandas.read_csv('ONSPD_MAY_2023_UK.csv', usecols=[2,11,12, 17,40], header=0 ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4621737",
   "metadata": {},
   "source": [
    "A handful of useful fields are joined to the property records based on the postcode field:\n",
    "Easting and northing projected coordinates in EPSG 27700 or the 'British National Grid' allow use to locate the records.\n",
    "The urban-rural classification gives us an indicator for whether the property is in a broadly 'rural' or 'urban. area.\n",
    "The 'Government Office Region' gives a broad geographic breakdown of the type policy makers commonly understand in the UK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e78a1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "geocoded = joined.merge(onspd, left_on='postcode_y', right_on='pcds', how='left')\n",
    "urban_rural_class_dict = {\"A1\": \"Major Conurbation\", \"B1\": \"Minor Conurbation\", \"C1\": \"City and Town\", \"C2\": \"City and Town in a Sparse Setting\", \"D1\": \"Town and Fringe\", \"D2\":\"Town and Fringe in a Sparse Setting\", \"E1\": \"Village\", \"E2\": \"Village in a Sparse Setting\", \"F1\": \"Hamlets and Isolated Dwellings\", \"F2\": \"Hamlets and Isolated Dwellings in a Sparse Setting\"}\n",
    "geocoded['urbrur11'] = geocoded['ru11ind'].map(urban_rural_class_dict)\n",
    "urban_rural_class_dictb = {\"A1\": \"Urban\", \"B1\": \"Urban\", \"C1\": \"Urban\", \"C2\": \"Urban\", \"D1\": \"Rural\", \"D2\":\"Rural\", \"E1\": \"Rural\", \"E2\": \"Rural\", \"F1\": \"Rural\", \"F2\": \"Rural\"}\n",
    "geocoded['urbrur11b'] = geocoded['ru11ind'].map(urban_rural_class_dictb)\n",
    "prop_type_dict = {\"T\": \"Terraced\", \"S\": \"Semi-Detached\", \"F\": \"Flat/Maisonette\", \"D\": \"Detatched\", \"O\": \"Other\"}\n",
    "geocoded['typedesc'] = geocoded['proptype_x'].map(prop_type_dict)\n",
    "region_dict = {\"W99999999\": \"Wales\", \"E12000001\": \"North East\", \"E12000002\": \"North West\", \"E12000003\": \"Yorkshire and The Humber\", \"E12000004\": \"East Midlands\", \"E12000005\": \"West Midlands\", \"E12000006\": \"East of England\", \"E12000007\": \"London\", \"E12000008\": \"South East\", \"E12000009\": \"South West\"}\n",
    "geocoded['region'] = geocoded['rgn'].map(region_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cd1e92",
   "metadata": {},
   "source": [
    "The xy coordinate fields can then be used as 'point data' held in a geodataframe. The Coordinate Reference System (CRS) should be defined at this point to ensure 'points are in the right place in the world':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af7b0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = geopandas.GeoDataFrame(geocoded, geometry=geopandas.points_from_xy(geocoded.oseast1m,geocoded.osnrth1m)) \n",
    "gdf = gdf.set_crs(27700, allow_override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5f76e4",
   "metadata": {},
   "source": [
    "The points can be exported and written to disk at this point for use elsewhere, particulary for web mapping if useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5348a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "geocoded.to_csv('price_paid_2012_2022.csv')\n",
    "gdf.to_file('price_paid_2012_2022.geojson', driver='geojson')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f19da48",
   "metadata": {},
   "source": [
    "The records of property type 'Other' can be dropped as the class is both unhelpful and counts are too small to be statistically significant for the segmentations produced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31b78cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "geocoded.drop(geocoded[geocoded.typedesc == 'Other'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b6b739",
   "metadata": {},
   "source": [
    "The data is grouped to examine multi-variate statistics. \n",
    "\n",
    "The broad urban-rural split is used in order to allow enough record counts for statistical significance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c020d6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'geocoded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mgeocoded\u001b[49m\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murbrur11b\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtypedesc\u001b[39m\u001b[38;5;124m'\u001b[39m])[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mperchange\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mplot(kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbarh\u001b[39m\u001b[38;5;124m'\u001b[39m, color \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#f78da7\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m% c\u001b[39;00m\u001b[38;5;124mhange price paid 2012-2022\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# all of labels and title need changing if data changes\u001b[39;00m\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUrban Rural Classification by property type\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'geocoded' is not defined"
     ]
    }
   ],
   "source": [
    "geocoded.groupby(['urbrur11b', 'typedesc'])['perchange'].mean().plot(kind='barh', color = '#f78da7')\n",
    "plt.xlabel(\"% change price paid 2012-2022\")\n",
    "plt.ylabel(\"Urban Rural Classification by property type\")\n",
    "plt.title(\"Average property value uplift 2012-2022 by Urban Rural Classification and property type in England and Wales\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71de1d05",
   "metadata": {},
   "source": [
    "NARRATIVE ON URBAN RURAL RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2e08de",
   "metadata": {},
   "source": [
    "Results can also be grouped by property type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f4c877",
   "metadata": {},
   "outputs": [],
   "source": [
    "geocoded.groupby(['typedesc'])['perchange'].mean().reindex(['Flat/Maisonette', 'Terraced', 'Semi-Detached', 'Detatched']).plot(kind='barh', color = '#f78da7')\n",
    "plt.xlabel(\"% change price paid 2012-2022\")\n",
    "plt.ylabel(\"Property type\")\n",
    "plt.title(\"Average property value uplift 2012-2022 by property type in England and Wales\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc854bb5",
   "metadata": {},
   "source": [
    "NARRATIVE ON TYPE RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58e48d0",
   "metadata": {},
   "source": [
    "Also grouped by both region and property type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957ab888",
   "metadata": {},
   "outputs": [],
   "source": [
    "geocoded.groupby(['region', 'typedesc'])['perchange'].mean().plot(kind='barh', color = '#f78da7')\n",
    "plt.xlabel(\"% change price paid 2012-2022\") \n",
    "plt.ylabel(\"Region by property type\")\n",
    "plt.title(\"Average property value uplift 2012-2022 by Region and property type in England and Wales\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01158f42",
   "metadata": {},
   "source": [
    "NARRATIVE ON REGION AND PROPERTY TYPE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1296edfe",
   "metadata": {},
   "source": [
    "Also simply by region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a400b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "geocoded.groupby(['region'])['perchange'].mean().plot(kind='barh', color = '#f78da7')\n",
    "plt.xlabel(\"% change price paid 2012-2022\")\n",
    "plt.ylabel(\"Region by region\")\n",
    "plt.title(\"Average property value uplift 2012-2022 by region in England and Wales\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71952cd",
   "metadata": {},
   "source": [
    "Descriptive statistics can be compared, and for future changes to the input data i.e. different years, calculating record-counts are also wise. These can also be exported as tables for use elsewhere:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ac4379",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_proptype = geocoded.groupby(['urbrur11'])['perchange'].mean()\n",
    "groupby_proptype.to_csv('perchange_by_urban_rural_mean.csv')\n",
    "groupby_urbanrural = geocoded.groupby(['typedesc'])['perchange'].mean()\n",
    "groupby_urbanrural.to_csv('perchange_by_proptype_mean.csv')\n",
    "groupby_urbanrural_pt_ = geocoded.groupby(['typedesc', 'urbrur11b'])['perchange'].mean()\n",
    "groupby_urbanrural_pt_.to_csv('perchange_by_proptype_urban_rural_mean.csv')\n",
    "\n",
    "groupby_region_proptype = geocoded.groupby(['region', 'typedesc'])['perchange'].mean()\n",
    "groupby_region_proptype.to_csv('perchange_by_region_proptype_mean.csv')\n",
    "\n",
    "groupby_region = geocoded.groupby(['region'])['perchange'].mean()\n",
    "groupby_region.to_csv('perchange_by_region_mean.csv')\n",
    "\n",
    "groupby_proptypeb = geocoded.groupby(['urbrur11'])['perchange'].count()\n",
    "groupby_proptypeb.to_csv('perchange_by_urban_rural_counts.csv')\n",
    "groupby_urbanruralb = geocoded.groupby(['typedesc'])['perchange'].count()\n",
    "groupby_urbanruralb.to_csv('perchange_by_proptype_counts.csv')\n",
    "groupby_urbanrural_ptb = geocoded.groupby(['typedesc', 'urbrur11'])['perchange'].count()\n",
    "groupby_urbanrural_ptb.to_csv('perchange_by_proptype_urban_ruralall_counts.csv')\n",
    "groupby_urbanrural_ptc = geocoded.groupby(['typedesc', 'urbrur11b'])['perchange'].count()\n",
    "groupby_urbanrural_ptc.to_csv('perchange_by_proptype_urban_rural_counts.csv')\n",
    "\n",
    "groupby_region_proptypeb = geocoded.groupby(['region', 'typedesc'])['perchange'].count()\n",
    "groupby_region_proptypeb.to_csv('perchange_by_region_proptype_counts.csv')\n",
    "\n",
    "groupby_regionb = geocoded.groupby(['region'])['perchange'].count()\n",
    "groupby_regionb.to_csv('perchange_by_region_counts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8976564",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTES FROM IF EMAIL ON STRENGTHS AND DRAWBACKS OF THE APPROACH"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
